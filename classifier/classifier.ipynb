{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi9MMj6AJEk-",
        "colab_type": "code",
        "outputId": "51515faf-cf80-4f0d-bf60-6629056bf86f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd8TKmZmX1GT",
        "colab_type": "code",
        "outputId": "435cee81-3f89-414d-8503-817e2bf638d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oMsHGJh8RxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars=\"abcdefghijklmnopqrstuvwxyz0123456789 -,;.!?:'\\\"/\\|_@#$%ˆ&*˜‘+-=()[]{}<>\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D7t7VB9qlGj",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytey2KOwqlcd",
        "colab_type": "code",
        "outputId": "51f46fd4-ce3c-406a-9713-cf55cd4fc509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "\n",
        "df = pd.read_csv('drive/My Drive/data.tar.gz', compression='gzip')\n",
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data.csv</th>\n",
              "      <th>line</th>\n",
              "      <th>is_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13166904</th>\n",
              "      <td>java</td>\n",
              "      <td>b'import org.springframework.boot.autoconfigur...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166905</th>\n",
              "      <td>java</td>\n",
              "      <td>b'import org.springframework.boot.test.autocon...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166906</th>\n",
              "      <td>java</td>\n",
              "      <td>b'@springbootapplication'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166907</th>\n",
              "      <td>java</td>\n",
              "      <td>b'public class examplewebfluxapplication {'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166908</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         data.csv                                               line  is_code\n",
              "13166904     java  b'import org.springframework.boot.autoconfigur...      1.0\n",
              "13166905     java  b'import org.springframework.boot.test.autocon...      1.0\n",
              "13166906     java                          b'@springbootapplication'      1.0\n",
              "13166907     java        b'public class examplewebfluxapplication {'      1.0\n",
              "13166908      NaN                                                NaN      NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_GOfDV0Li09",
        "colab_type": "code",
        "outputId": "c9285643-d491-4528-c330-7b2cc4285795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1992
        }
      },
      "source": [
        "df.drop(index=13166908)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data.csv</th>\n",
              "      <th>line</th>\n",
              "      <th>is_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'tslint:disable:max-line-length'</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'@deprecated deprecated in favor of static co...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'@deprecated deprecated in favor of static co...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'@deprecated deprecated in favor of static co...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'@deprecated deprecated in favor of static co...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'@deprecated deprecated in favor of static co...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'@deprecated deprecated in favor of static co...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'@deprecated deprecated in favor of static co...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'@deprecated deprecated in favor of static co...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'@deprecated deprecated in favor of static co...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'@deprecated deprecated in favor of static co...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'@deprecated deprecated in favor of static co...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'@deprecated deprecated in favor of static co...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'@deprecated deprecated in favor of static co...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'@deprecated deprecated in favor of static co...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'tslint:enable:max-line-length'</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'@deprecated deprecated in favor of static {@...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ts</td>\n",
              "      <td>b'if the first and only other argument besides...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ts</td>\n",
              "      <td>b\"assume it's been called with `combinelatest(...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>java</td>\n",
              "      <td>b'licensed to the apache software foundation (...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>java</td>\n",
              "      <td>b'contributor license agreements.  see the not...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>java</td>\n",
              "      <td>b'this work for additional information regardi...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>java</td>\n",
              "      <td>b'the asf licenses this file to you under the ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>java</td>\n",
              "      <td>b'(the \"license\"); you may not use this file e...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>java</td>\n",
              "      <td>b'the license.  you may obtain a copy of the l...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>java</td>\n",
              "      <td>b'http:www.apache.org/licenses/license-2.0'</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>java</td>\n",
              "      <td>b'unless required by applicable law or agreed ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>java</td>\n",
              "      <td>b'distributed under the license is distributed...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>java</td>\n",
              "      <td>b'without warranties or conditions of any kind...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>java</td>\n",
              "      <td>b'see the license for the specific language go...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166878</th>\n",
              "      <td>java</td>\n",
              "      <td>b'const fittedmercator = mercatorwithoptions.f...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166879</th>\n",
              "      <td>java</td>\n",
              "      <td>b'padding: 10,'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166880</th>\n",
              "      <td>java</td>\n",
              "      <td>b'offset: [10, 20],'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166881</th>\n",
              "      <td>java</td>\n",
              "      <td>b'});'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166882</th>\n",
              "      <td>java</td>\n",
              "      <td>b'const equalfitted = fittedmercator.equals(me...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166883</th>\n",
              "      <td>java</td>\n",
              "      <td>b'const distancescalesinputzoom = {'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166884</th>\n",
              "      <td>java</td>\n",
              "      <td>b'longitude: 1,'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166885</th>\n",
              "      <td>java</td>\n",
              "      <td>b'latitude: 2,'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166886</th>\n",
              "      <td>java</td>\n",
              "      <td>b'zoom: 1,'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166887</th>\n",
              "      <td>java</td>\n",
              "      <td>b'const { pixelsperdegree } = getdistancescale...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166888</th>\n",
              "      <td>java</td>\n",
              "      <td>b'const { pixelsperdegree2 } = getdistancescal...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166889</th>\n",
              "      <td>java</td>\n",
              "      <td>b'...distancescalesinputzoom,'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166890</th>\n",
              "      <td>java</td>\n",
              "      <td>b'highprecision: true,'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166891</th>\n",
              "      <td>java</td>\n",
              "      <td>b'});'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166892</th>\n",
              "      <td>java</td>\n",
              "      <td>b'const distancescalesinputscale = {'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166893</th>\n",
              "      <td>java</td>\n",
              "      <td>b'longitude: 1,'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166894</th>\n",
              "      <td>java</td>\n",
              "      <td>b'latitude: 2,'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166895</th>\n",
              "      <td>java</td>\n",
              "      <td>b'scale: 1,'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166896</th>\n",
              "      <td>java</td>\n",
              "      <td>b'const { metersperpixel } = getdistancescales...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166897</th>\n",
              "      <td>java</td>\n",
              "      <td>b'const { pixelspermeter2 } = getdistancescale...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166898</th>\n",
              "      <td>java</td>\n",
              "      <td>b'...distancescalesinputscale,'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166899</th>\n",
              "      <td>java</td>\n",
              "      <td>b'highprecision: true,'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166900</th>\n",
              "      <td>java</td>\n",
              "      <td>b'});'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166901</th>\n",
              "      <td>java</td>\n",
              "      <td>b'const [a, b] = addmeterstolnglat([1, 2], [3,...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166902</th>\n",
              "      <td>java</td>\n",
              "      <td>b'const [c, d, e] = addmeterstolnglat([1, 2, 3...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166903</th>\n",
              "      <td>java</td>\n",
              "      <td>b'package org.springframework.boot.test.autoco...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166904</th>\n",
              "      <td>java</td>\n",
              "      <td>b'import org.springframework.boot.autoconfigur...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166905</th>\n",
              "      <td>java</td>\n",
              "      <td>b'import org.springframework.boot.test.autocon...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166906</th>\n",
              "      <td>java</td>\n",
              "      <td>b'@springbootapplication'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13166907</th>\n",
              "      <td>java</td>\n",
              "      <td>b'public class examplewebfluxapplication {'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13166908 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         data.csv                                               line  is_code\n",
              "0              ts                  b'tslint:disable:max-line-length'      0.0\n",
              "1              ts  b'@deprecated deprecated in favor of static co...      0.0\n",
              "2              ts  b'@deprecated deprecated in favor of static co...      0.0\n",
              "3              ts  b'@deprecated deprecated in favor of static co...      0.0\n",
              "4              ts  b'@deprecated deprecated in favor of static co...      0.0\n",
              "5              ts  b'@deprecated deprecated in favor of static co...      0.0\n",
              "6              ts  b'@deprecated deprecated in favor of static co...      0.0\n",
              "7              ts  b'@deprecated deprecated in favor of static co...      0.0\n",
              "8              ts  b'@deprecated deprecated in favor of static co...      0.0\n",
              "9              ts  b'@deprecated deprecated in favor of static co...      0.0\n",
              "10             ts  b'@deprecated deprecated in favor of static co...      0.0\n",
              "11             ts  b'@deprecated deprecated in favor of static co...      0.0\n",
              "12             ts  b'@deprecated deprecated in favor of static co...      0.0\n",
              "13             ts  b'@deprecated deprecated in favor of static co...      0.0\n",
              "14             ts  b'@deprecated deprecated in favor of static co...      0.0\n",
              "15             ts                   b'tslint:enable:max-line-length'      0.0\n",
              "16             ts  b'@deprecated deprecated in favor of static {@...      0.0\n",
              "17             ts  b'if the first and only other argument besides...      0.0\n",
              "18             ts  b\"assume it's been called with `combinelatest(...      0.0\n",
              "19           java  b'licensed to the apache software foundation (...      0.0\n",
              "20           java  b'contributor license agreements.  see the not...      0.0\n",
              "21           java  b'this work for additional information regardi...      0.0\n",
              "22           java  b'the asf licenses this file to you under the ...      0.0\n",
              "23           java  b'(the \"license\"); you may not use this file e...      0.0\n",
              "24           java  b'the license.  you may obtain a copy of the l...      0.0\n",
              "25           java        b'http:www.apache.org/licenses/license-2.0'      0.0\n",
              "26           java  b'unless required by applicable law or agreed ...      0.0\n",
              "27           java  b'distributed under the license is distributed...      0.0\n",
              "28           java  b'without warranties or conditions of any kind...      0.0\n",
              "29           java  b'see the license for the specific language go...      0.0\n",
              "...           ...                                                ...      ...\n",
              "13166878     java  b'const fittedmercator = mercatorwithoptions.f...      1.0\n",
              "13166879     java                                    b'padding: 10,'      1.0\n",
              "13166880     java                               b'offset: [10, 20],'      1.0\n",
              "13166881     java                                             b'});'      1.0\n",
              "13166882     java  b'const equalfitted = fittedmercator.equals(me...      1.0\n",
              "13166883     java               b'const distancescalesinputzoom = {'      1.0\n",
              "13166884     java                                   b'longitude: 1,'      1.0\n",
              "13166885     java                                    b'latitude: 2,'      1.0\n",
              "13166886     java                                        b'zoom: 1,'      1.0\n",
              "13166887     java  b'const { pixelsperdegree } = getdistancescale...      1.0\n",
              "13166888     java  b'const { pixelsperdegree2 } = getdistancescal...      1.0\n",
              "13166889     java                     b'...distancescalesinputzoom,'      1.0\n",
              "13166890     java                            b'highprecision: true,'      1.0\n",
              "13166891     java                                             b'});'      1.0\n",
              "13166892     java              b'const distancescalesinputscale = {'      1.0\n",
              "13166893     java                                   b'longitude: 1,'      1.0\n",
              "13166894     java                                    b'latitude: 2,'      1.0\n",
              "13166895     java                                       b'scale: 1,'      1.0\n",
              "13166896     java  b'const { metersperpixel } = getdistancescales...      1.0\n",
              "13166897     java  b'const { pixelspermeter2 } = getdistancescale...      1.0\n",
              "13166898     java                    b'...distancescalesinputscale,'      1.0\n",
              "13166899     java                            b'highprecision: true,'      1.0\n",
              "13166900     java                                             b'});'      1.0\n",
              "13166901     java  b'const [a, b] = addmeterstolnglat([1, 2], [3,...      1.0\n",
              "13166902     java  b'const [c, d, e] = addmeterstolnglat([1, 2, 3...      1.0\n",
              "13166903     java  b'package org.springframework.boot.test.autoco...      1.0\n",
              "13166904     java  b'import org.springframework.boot.autoconfigur...      1.0\n",
              "13166905     java  b'import org.springframework.boot.test.autocon...      1.0\n",
              "13166906     java                          b'@springbootapplication'      1.0\n",
              "13166907     java        b'public class examplewebfluxapplication {'      1.0\n",
              "\n",
              "[13166908 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3XAejReQWnU",
        "colab_type": "code",
        "outputId": "0deedda5-677e-4aa8-a1a4-0d55660129b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "VAL_SIZE = 0.2\n",
        "\n",
        "idx = list(df.index)\n",
        "\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "train_idx = idx[int(VAL_SIZE*len(idx)):]\n",
        "val_idx = idx[:int(VAL_SIZE*len(idx))]\n",
        "\n",
        "train = df.loc[train_idx, :]\n",
        "val = df.loc[val_idx, :]\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data.csv</th>\n",
              "      <th>line</th>\n",
              "      <th>is_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9975770</th>\n",
              "      <td>java</td>\n",
              "      <td>b'bigtens[] = { 1e16, 1e32, 1e64, 1e128, 1e256...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5026466</th>\n",
              "      <td>java</td>\n",
              "      <td>b'xmlvm_enter_method(\"org.apache.harmony.luni....</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6832522</th>\n",
              "      <td>java</td>\n",
              "      <td>b'end = getnextbaseoffset(text, end, strsrch-&gt;...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3148306</th>\n",
              "      <td>java</td>\n",
              "      <td>b'const checktypes = process.env[\"node_env\"] !...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8530647</th>\n",
              "      <td>java</td>\n",
              "      <td>b'if (path &gt;= basename) return_node_and_errno(...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        data.csv                                               line  is_code\n",
              "9975770     java  b'bigtens[] = { 1e16, 1e32, 1e64, 1e128, 1e256...      1.0\n",
              "5026466     java  b'xmlvm_enter_method(\"org.apache.harmony.luni....      1.0\n",
              "6832522     java  b'end = getnextbaseoffset(text, end, strsrch->...      1.0\n",
              "3148306     java  b'const checktypes = process.env[\"node_env\"] !...      1.0\n",
              "8530647     java  b'if (path >= basename) return_node_and_errno(...      1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w24FBc690QbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char2idx = {c: i + 2 for i, c in enumerate(chars)}\n",
        "char2idx[\"UNK\"] = 1\n",
        "char2idx[\"PAD\"] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtaWG6rS25KK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "max_len = 200\n",
        "def transform_sentences(df2):\n",
        "  X_char = []\n",
        "  for sentence in df2['line']:\n",
        "    sentence =  sentence[2:-1].lower()\n",
        "    sent_seq = []\n",
        "    for i in range(max_len):\n",
        "      try:\n",
        "        value = char2idx.get(sentence[i])\n",
        "        if value == None:\n",
        "          sent_seq.append(char2idx[\"UNK\"])\n",
        "        else:\n",
        "          sent_seq.append(value)\n",
        "      except:\n",
        "        sent_seq.append(char2idx.get(\"PAD\"))\n",
        "    X_char.append(np.array(sent_seq))\n",
        "  X_char = pad_sequences(maxlen=max_len, sequences=X_char, value=char2idx[\"PAD\"], padding='post', truncating='post')\n",
        "  #print(X_char[:5])\n",
        "  return X_char"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDM8S0hv5u0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, Dropout\n",
        "from keras.layers import Bidirectional\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J0rw3Bu-jB_",
        "colab_type": "code",
        "outputId": "19f7cb47-9841-42d4-900e-8a47411ae3bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "char_in = Input(shape=(max_len,))\n",
        "emb_char = Embedding(input_dim=len(chars) + 2, output_dim=16,\n",
        "                           input_length=max_len, mask_zero=True)(char_in)\n",
        "main_lstm = LSTM(units=100, return_sequences=False,\n",
        "                               recurrent_dropout=0.8)(emb_char)\n",
        "out = (Dense(8,input_shape=(16,), activation='relu'))(main_lstm)\n",
        "out = Dropout(0.2)(out)\n",
        "out = (Dense(1, activation='sigmoid'))(out)\n",
        "model = Model( char_in, out)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 200, 32)           2304      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 808       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 56,321\n",
            "Trainable params: 56,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIw2apetEZpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JEsnnuXEzNn",
        "colab_type": "code",
        "outputId": "9400fa0d-aec3-4327-eda1-269984bc12d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14278
        }
      },
      "source": [
        "eval = []\n",
        "for i in range(20):\n",
        "  print(i)\n",
        "  filepath=\"drive/My Drive/separatecode_sample\"+str(i)+\"-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "  callbacks_list = [checkpoint]\n",
        "  df2 = train.sample(n=100000)\n",
        "  X = transform_sentences(df2)\n",
        "  X_train,X_test = X[:80000],X[80000:]\n",
        "  model.fit(X_train, df2[:80000]['is_code'], epochs=10, batch_size=1024, validation_split=0.2, callbacks=callbacks_list)\n",
        "  \n",
        "  p = model.evaluate(X_test,df2[80000:]['is_code'])\n",
        "  eval.append(p)\n",
        "  print(p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3 19  6  2 12 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [17 22  3 13 10  4 38 23 16 10  5 38  8  6 21 23  6  9 10  4 13  6  5  6\n",
            "  21  2 10 13 20 24  9  6 15 22 20  6 19 15  2 14  6 10 20 15 22 13 13 20\n",
            "   9 16 22 13  5 21  9 19 16 24  6 25  4  6 17 21 10 16 15 64 65 38 68  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [21 16 12  6 15 45 38 47 12  6 26 24 16 19  5 47 40  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [19  6 21 22 19 15 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38\n",
            "  28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38\n",
            "  28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38\n",
            "  28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 64000 samples, validate on 16000 samples\n",
            "Epoch 1/10\n",
            "64000/64000 [==============================] - 33s 513us/step - loss: 0.4658 - acc: 0.8179 - val_loss: 0.2929 - val_acc: 0.8866\n",
            "Epoch 2/10\n",
            "64000/64000 [==============================] - 31s 479us/step - loss: 0.2513 - acc: 0.9163 - val_loss: 0.2070 - val_acc: 0.9296\n",
            "Epoch 3/10\n",
            "64000/64000 [==============================] - 29s 458us/step - loss: 0.2118 - acc: 0.9310 - val_loss: 0.1967 - val_acc: 0.9336\n",
            "Epoch 4/10\n",
            "64000/64000 [==============================] - 29s 458us/step - loss: 0.2048 - acc: 0.9344 - val_loss: 0.1927 - val_acc: 0.9348\n",
            "Epoch 5/10\n",
            "64000/64000 [==============================] - 29s 460us/step - loss: 0.2005 - acc: 0.9355 - val_loss: 0.1901 - val_acc: 0.9361\n",
            "Epoch 6/10\n",
            "64000/64000 [==============================] - 30s 461us/step - loss: 0.1992 - acc: 0.9357 - val_loss: 0.1879 - val_acc: 0.9365\n",
            "Epoch 7/10\n",
            "64000/64000 [==============================] - 29s 450us/step - loss: 0.1993 - acc: 0.9360 - val_loss: 0.1872 - val_acc: 0.9364\n",
            "Epoch 8/10\n",
            "64000/64000 [==============================] - 29s 457us/step - loss: 0.1936 - acc: 0.9378 - val_loss: 0.1862 - val_acc: 0.9359\n",
            "Epoch 9/10\n",
            "64000/64000 [==============================] - 29s 452us/step - loss: 0.1930 - acc: 0.9378 - val_loss: 0.1833 - val_acc: 0.9355\n",
            "Epoch 10/10\n",
            "64000/64000 [==============================] - 29s 454us/step - loss: 0.1911 - acc: 0.9381 - val_loss: 0.1838 - val_acc: 0.9358\n",
            "20000/20000 [==============================] - 85s 4ms/step\n",
            "[0.18944720185101033, 0.9339]\n",
            "[[ 7 10 13 21  6 19  6  5 23  2 13 22  6 20 42  2  5  5 64 23  2 13 22  6\n",
            "  65 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38\n",
            "  28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38\n",
            "  28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38\n",
            "  28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 4 16 17 26 19 10  8  9 21 38 64  4 65 38  7  2  4  6  3 16 16 12 40 38\n",
            "  10 15  4 42 38  2 15  5 38 10 21 20 38  2  7  7 10 13 10  2 21  6 20 42\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [16 19 38 10 14 17 13 10  6  5 42 38 20  6  6 38 21  9  6 38 13 10  4  6\n",
            "  15 20  6 38  7 16 19 38 21  9  6 38 20 17  6  4 10  7 10  4 38 13  2 15\n",
            "   8 22  2  8  6 38  8 16 23  6 19 15 10 15  8 38 17  6 19 14 10 20 20 10\n",
            "  16 15 20 38  2 15  5 38 13 10 14 10 21  2 21 10 16 15 20 38 22 15  5  6\n",
            "  19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 7 10 13  6 38 63 38  8 27 16 17  6 15 64 58  2 19  8 23 40 38 47 19  3\n",
            "  47 65 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]]\n",
            "Train on 64000 samples, validate on 16000 samples\n",
            "Epoch 1/10\n",
            "64000/64000 [==============================] - 28s 436us/step - loss: 0.1907 - acc: 0.9367 - val_loss: 0.1855 - val_acc: 0.9344\n",
            "Epoch 2/10\n",
            "64000/64000 [==============================] - 29s 446us/step - loss: 0.1881 - acc: 0.9378 - val_loss: 0.1831 - val_acc: 0.9354\n",
            "Epoch 3/10\n",
            "64000/64000 [==============================] - 29s 452us/step - loss: 0.1847 - acc: 0.9382 - val_loss: 0.1794 - val_acc: 0.9367\n",
            "Epoch 4/10\n",
            "64000/64000 [==============================] - 29s 447us/step - loss: 0.1827 - acc: 0.9388 - val_loss: 0.1759 - val_acc: 0.9387\n",
            "Epoch 5/10\n",
            "64000/64000 [==============================] - 28s 444us/step - loss: 0.1778 - acc: 0.9408 - val_loss: 0.1747 - val_acc: 0.9380\n",
            "Epoch 6/10\n",
            "64000/64000 [==============================] - 28s 441us/step - loss: 0.1761 - acc: 0.9410 - val_loss: 0.1715 - val_acc: 0.9408\n",
            "Epoch 7/10\n",
            "64000/64000 [==============================] - 28s 438us/step - loss: 0.1742 - acc: 0.9414 - val_loss: 0.1707 - val_acc: 0.9387\n",
            "Epoch 8/10\n",
            "64000/64000 [==============================] - 29s 446us/step - loss: 0.1716 - acc: 0.9424 - val_loss: 0.1696 - val_acc: 0.9403\n",
            "Epoch 9/10\n",
            "64000/64000 [==============================] - 28s 438us/step - loss: 0.1696 - acc: 0.9430 - val_loss: 0.1680 - val_acc: 0.9397\n",
            "Epoch 10/10\n",
            "64000/64000 [==============================] - 28s 439us/step - loss: 0.1672 - acc: 0.9443 - val_loss: 0.1673 - val_acc: 0.9409\n",
            "20000/20000 [==============================] - 84s 4ms/step\n",
            "[0.15116400394290685, 0.94735]\n",
            "[[ 2 23 51 13 16  8 64  2 23  4 21 25 40 38  2 23 51 13 16  8 51  6 19 19\n",
            "  16 19 40 38 47  6 19 19 16 19 45 38  7 19  2 14  6 49 46 20 38 13 10 15\n",
            "   6 20 10 27  6 38 10 20 38 21 16 16 38 20 14  2 13 13 38  7 16 19 38 21\n",
            "   9  6 38 10 14  2  8  6 49 49 15 47 65 41  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [20 22  3 20  4 19 10  3  6 19 42  6 19 19 16 19 64  6 19 19 65 41  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 4 16 17 26 19 10  8  9 21 38 64  4 65 38 30 28 28 30 62 30 28 28 32 38\n",
            "  14 10  4  9  2  6 13 38 15 10  6  5  6 19 14  2 26  6 19 38 70 14 10  4\n",
            "   9  2  6 13 15 10 52  8 14 25 42  2 21 71  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [21  6 20 21  5  2 21  6 17  2 19 20  6 64 47  5  6  4 38 30 33 38 29 37\n",
            "  37 33 38 29 45 31 28 38  2 14 38 64 17 14 65 47 40 38 47 36 29 37 36 33\n",
            "  33 28 28 28 28 28 28 38 61 38 21 10 14  6 27 16 15  6 16  7  7 20  6 21\n",
            "  47 65 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [52 16 23  6 19 19 10  5  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]]\n",
            "Train on 64000 samples, validate on 16000 samples\n",
            "Epoch 1/10\n",
            "64000/64000 [==============================] - 29s 454us/step - loss: 0.1697 - acc: 0.9421 - val_loss: 0.1464 - val_acc: 0.9494\n",
            "Epoch 2/10\n",
            "64000/64000 [==============================] - 28s 441us/step - loss: 0.1667 - acc: 0.9432 - val_loss: 0.1478 - val_acc: 0.9488\n",
            "Epoch 3/10\n",
            "64000/64000 [==============================] - 28s 441us/step - loss: 0.1662 - acc: 0.9431 - val_loss: 0.1440 - val_acc: 0.9506\n",
            "Epoch 4/10\n",
            "64000/64000 [==============================] - 29s 459us/step - loss: 0.1639 - acc: 0.9439 - val_loss: 0.1436 - val_acc: 0.9511\n",
            "Epoch 5/10\n",
            "64000/64000 [==============================] - 30s 468us/step - loss: 0.1628 - acc: 0.9446 - val_loss: 0.1438 - val_acc: 0.9506\n",
            "Epoch 6/10\n",
            "64000/64000 [==============================] - 29s 460us/step - loss: 0.1613 - acc: 0.9465 - val_loss: 0.1432 - val_acc: 0.9518\n",
            "Epoch 7/10\n",
            "64000/64000 [==============================] - 29s 452us/step - loss: 0.1592 - acc: 0.9458 - val_loss: 0.1417 - val_acc: 0.9515\n",
            "Epoch 8/10\n",
            "64000/64000 [==============================] - 29s 454us/step - loss: 0.1587 - acc: 0.9463 - val_loss: 0.1410 - val_acc: 0.9515\n",
            "Epoch 9/10\n",
            "64000/64000 [==============================] - 28s 444us/step - loss: 0.1553 - acc: 0.9478 - val_loss: 0.1387 - val_acc: 0.9527\n",
            "Epoch 10/10\n",
            "64000/64000 [==============================] - 29s 449us/step - loss: 0.1550 - acc: 0.9481 - val_loss: 0.1392 - val_acc: 0.9517\n",
            "20000/20000 [==============================] - 84s 4ms/step\n",
            "[0.14515626840740442, 0.94725]\n",
            "[[21  6 20 21 64 47 19  6 21 22 19 15 10 15  8 38 15 22 13 13 38 20  9  2\n",
            "  19  6  5 38 17 16 10 15 21  6 19 38  7 19 16 14 38 10 15 21  6 19  7  2\n",
            "   4  6 20 38 10 14 17 13  6 14  6 15 21  6  5 38 10 15 38 11 20 38  4 16\n",
            "   5  6 38  5 16  6 20 38 15 16 21 38 13  6  2 12 47 40 38  7 22 15  4 21\n",
            "  10 16 15 64 65 38 68  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [53 38 21 10 21 13  6 20 38  2 19  6 38  5 22 17 13 10  4  2 21  6 20 40\n",
            "  38 14  2 12  6 38 21  9  6 14 38 22 15 10 18 22  6  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 3  6  7 16 19  6  6  2  4  9 64 64 65 38 63 71 38 68  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [66  8 19  2 17  9 10  4 67 64  9 21 21 17 20 45  6  4 16 14  7  6 42  8\n",
            "  10 21  9 22  3 42 10 16 48  6  4  9  2 19 21 20 62  5 16  4 48 17 22  3\n",
            "  13 10  4 48  6 15 48 16 17 21 10 16 15 42  9 21 14 13 53  8 19  2 17  9\n",
            "  10  4 42  6 13  6 14  6 15 21 20 65  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [19  6 21 22 19 15 38  4 19  6  2 21  6 10  5  6 15 21 10  7 10  6 19 64\n",
            "  47  7 22 15  4 21 10 16 15 47 65 41  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]]\n",
            "Train on 64000 samples, validate on 16000 samples\n",
            "Epoch 1/10\n",
            "64000/64000 [==============================] - 29s 448us/step - loss: 0.1504 - acc: 0.9504 - val_loss: 0.1508 - val_acc: 0.9472\n",
            "Epoch 2/10\n",
            "64000/64000 [==============================] - 28s 444us/step - loss: 0.1486 - acc: 0.9512 - val_loss: 0.1507 - val_acc: 0.9474\n",
            "Epoch 3/10\n",
            "64000/64000 [==============================] - 29s 449us/step - loss: 0.1476 - acc: 0.9512 - val_loss: 0.1489 - val_acc: 0.9483\n",
            "Epoch 4/10\n",
            "64000/64000 [==============================] - 28s 443us/step - loss: 0.1455 - acc: 0.9523 - val_loss: 0.1497 - val_acc: 0.9478\n",
            "Epoch 5/10\n",
            "64000/64000 [==============================] - 29s 453us/step - loss: 0.1457 - acc: 0.9521 - val_loss: 0.1484 - val_acc: 0.9489\n",
            "Epoch 6/10\n",
            "64000/64000 [==============================] - 29s 448us/step - loss: 0.1441 - acc: 0.9532 - val_loss: 0.1458 - val_acc: 0.9496\n",
            "Epoch 7/10\n",
            "64000/64000 [==============================] - 29s 447us/step - loss: 0.1425 - acc: 0.9539 - val_loss: 0.1464 - val_acc: 0.9492\n",
            "Epoch 8/10\n",
            "64000/64000 [==============================] - 29s 447us/step - loss: 0.1409 - acc: 0.9544 - val_loss: 0.1454 - val_acc: 0.9507\n",
            "Epoch 9/10\n",
            "64000/64000 [==============================] - 29s 456us/step - loss: 0.1396 - acc: 0.9552 - val_loss: 0.1437 - val_acc: 0.9514\n",
            "Epoch 10/10\n",
            "64000/64000 [==============================] - 28s 443us/step - loss: 0.1398 - acc: 0.9551 - val_loss: 0.1418 - val_acc: 0.9508\n",
            "20000/20000 [==============================] - 83s 4ms/step\n",
            "[0.13374113343954086, 0.9545]\n",
            "[[ 2  7 14 51 21 16 12  6 15 51  7  2 14 10 13 26 15  2 14  6 40  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [10  7 38 64 64 19  6 21 38 63 38 15 23  6 15  4 51 17 22 20  9 51  4 16\n",
            "  15 21  6 25 21 64  2 23  4 21 25 65 65 38 70 38 28 65  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 6 25 17  6  4 21 64 19  6 20 22 13 21 20 42 20 21  2 21 22 20 65 42 21\n",
            "  16  6 18 22  2 13 64 46  6 19 19 16 19 46 65 41  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [19  6 21 22 19 15 38  2 17 17 41  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [10  7 38 64 13 16  2  5  4 16 15 21  6 25 21 65 38 68  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]]\n",
            "Train on 64000 samples, validate on 16000 samples\n",
            "Epoch 1/10\n",
            "64000/64000 [==============================] - 29s 448us/step - loss: 0.1430 - acc: 0.9537 - val_loss: 0.1389 - val_acc: 0.9523\n",
            "Epoch 2/10\n",
            "64000/64000 [==============================] - 29s 447us/step - loss: 0.1424 - acc: 0.9543 - val_loss: 0.1378 - val_acc: 0.9524\n",
            "Epoch 3/10\n",
            "64000/64000 [==============================] - 28s 445us/step - loss: 0.1417 - acc: 0.9547 - val_loss: 0.1367 - val_acc: 0.9526\n",
            "Epoch 4/10\n",
            "64000/64000 [==============================] - 29s 451us/step - loss: 0.1410 - acc: 0.9557 - val_loss: 0.1384 - val_acc: 0.9512\n",
            "Epoch 5/10\n",
            "64000/64000 [==============================] - 29s 448us/step - loss: 0.1392 - acc: 0.9560 - val_loss: 0.1375 - val_acc: 0.9522\n",
            "Epoch 6/10\n",
            "64000/64000 [==============================] - 28s 445us/step - loss: 0.1397 - acc: 0.9550 - val_loss: 0.1352 - val_acc: 0.9526\n",
            "Epoch 7/10\n",
            "64000/64000 [==============================] - 29s 454us/step - loss: 0.1382 - acc: 0.9562 - val_loss: 0.1363 - val_acc: 0.9522\n",
            "Epoch 8/10\n",
            "64000/64000 [==============================] - 29s 450us/step - loss: 0.1372 - acc: 0.9566 - val_loss: 0.1343 - val_acc: 0.9533\n",
            "Epoch 9/10\n",
            "64000/64000 [==============================] - 29s 447us/step - loss: 0.1369 - acc: 0.9559 - val_loss: 0.1338 - val_acc: 0.9543\n",
            "Epoch 10/10\n",
            "64000/64000 [==============================] - 29s 448us/step - loss: 0.1366 - acc: 0.9568 - val_loss: 0.1325 - val_acc: 0.9543\n",
            "20000/20000 [==============================] - 84s 4ms/step\n",
            "[0.13404911654889584, 0.9567]\n",
            "[[ 9  6  2  5  6 19 51  3 26 21  6 51  4 16 22 15 21 38 63 38 17 16 20 38\n",
            "  62 38 20 21  2 19 21 38 61 38 12 13 23 51  7 10 13 13 51 20 10 27  6 64\n",
            "  17 16 20 65 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [10 14 17 16 19 21 38 16 19  8 42  6 13  2 20 21 10  4 20  6  2 19  4  9\n",
            "  42 10 15  5  6 25 42 18 22  6 19 26 42 18 22  6 19 26  3 22 10 13  5  6\n",
            "  19 20 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 2 20 20  6 19 21  6 18 22  2 13 20 64 14  2 17 17 10 15  8 40 38 14  2\n",
            "  17 17  6 19 42 14  2 17 17 10 15  8 20 16 22 19  4  6 64 65 42 21 16 20\n",
            "  21 19 10 15  8 64 65 65 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 4  2 20  6 38 31 45  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [21  2 12  6 20 38  2 38  7 22 15  4 21 10 16 15 38  2 15  5 38 19  6 21\n",
            "  22 19 15 20 38  2 38 15  6 24 38 16 15  6 38 21  9  2 21 38 24 10 13 13\n",
            "  38  2 13 24  2 26 20 38  9  2 23  6 38  2 38 17  2 19 21 10  4 22 13  2\n",
            "  19 38  4 16 15 21  6 25 21 42  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]]\n",
            "Train on 64000 samples, validate on 16000 samples\n",
            "Epoch 1/10\n",
            "64000/64000 [==============================] - 29s 455us/step - loss: 0.1351 - acc: 0.9572 - val_loss: 0.1240 - val_acc: 0.9593\n",
            "Epoch 2/10\n",
            "64000/64000 [==============================] - 29s 454us/step - loss: 0.1338 - acc: 0.9586 - val_loss: 0.1230 - val_acc: 0.9583\n",
            "Epoch 3/10\n",
            "64000/64000 [==============================] - 28s 443us/step - loss: 0.1321 - acc: 0.9583 - val_loss: 0.1232 - val_acc: 0.9587\n",
            "Epoch 4/10\n",
            "64000/64000 [==============================] - 29s 459us/step - loss: 0.1328 - acc: 0.9586 - val_loss: 0.1215 - val_acc: 0.9594\n",
            "Epoch 5/10\n",
            "64000/64000 [==============================] - 29s 448us/step - loss: 0.1311 - acc: 0.9595 - val_loss: 0.1212 - val_acc: 0.9599\n",
            "Epoch 6/10\n",
            "64000/64000 [==============================] - 28s 445us/step - loss: 0.1313 - acc: 0.9591 - val_loss: 0.1199 - val_acc: 0.9603\n",
            "Epoch 7/10\n",
            "64000/64000 [==============================] - 28s 443us/step - loss: 0.1310 - acc: 0.9588 - val_loss: 0.1194 - val_acc: 0.9601\n",
            "Epoch 8/10\n",
            "64000/64000 [==============================] - 29s 448us/step - loss: 0.1298 - acc: 0.9599 - val_loss: 0.1193 - val_acc: 0.9601\n",
            "Epoch 9/10\n",
            "64000/64000 [==============================] - 28s 444us/step - loss: 0.1281 - acc: 0.9605 - val_loss: 0.1195 - val_acc: 0.9601\n",
            "Epoch 10/10\n",
            "64000/64000 [==============================] - 29s 450us/step - loss: 0.1279 - acc: 0.9605 - val_loss: 0.1166 - val_acc: 0.9598\n",
            "20000/20000 [==============================] - 84s 4ms/step\n",
            "[0.11962865576148034, 0.95995]\n",
            "[[52 21  9 19 16 24 20 38 10 13 13  6  8  2 13 20 21  2 21  6  6 25  4  6\n",
            "  17 21 10 16 15 38 10  7 38 21  9  6 38 15 16  5  6 38 20  9 16 22 13  5\n",
            "  38 15 16 21 38 20 21  2 19 21 38  3  6  4  2 22 20  6 38 21  9  6 38 10\n",
            "  15  5  6 25 38 10 20 38 22 15 20 22 17 17 16 19 21  6  5  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38\n",
            "  28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38\n",
            "  28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38\n",
            "  28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40 38 28 25 28 28 40  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [10  7 38 64  8  6 21  4 16 15 21  6 15 21 21 26 17  6 64 65 38 43 63 38\n",
            "  15 22 13 13 65 38 68  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [14 16  5 22 13  6 42  6 25 17 16 19 21 20 38 63 38 19  6 18 22 10 19  6\n",
            "  64 46 42 42 48 42 42 46 65  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [10 15 38 14 22 13 21 10 17 13  6 38 21 19  2 15 20  2  4 21 10 16 15 20\n",
            "  38  2 21 38 21  9  6 38 20  2 14  6 38 21 10 14  6 38 64 10  6 40 38 26\n",
            "  16 22 38 14 22 20 21 38 20  6 13 13 38 21  9  6 38 20 21 16  4 12 38  3\n",
            "   6  7 16 19  6 38 26 16 22 38  3 22 26 38  2  8  2 10 15 65  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]]\n",
            "Train on 64000 samples, validate on 16000 samples\n",
            "Epoch 1/10\n",
            "64000/64000 [==============================] - 28s 445us/step - loss: 0.1298 - acc: 0.9587 - val_loss: 0.1181 - val_acc: 0.9623\n",
            "Epoch 2/10\n",
            "64000/64000 [==============================] - 29s 451us/step - loss: 0.1301 - acc: 0.9589 - val_loss: 0.1173 - val_acc: 0.9621\n",
            "Epoch 3/10\n",
            "64000/64000 [==============================] - 29s 451us/step - loss: 0.1280 - acc: 0.9599 - val_loss: 0.1152 - val_acc: 0.9634\n",
            "Epoch 4/10\n",
            "64000/64000 [==============================] - 28s 443us/step - loss: 0.1272 - acc: 0.9600 - val_loss: 0.1164 - val_acc: 0.9637\n",
            "Epoch 5/10\n",
            "64000/64000 [==============================] - 29s 450us/step - loss: 0.1273 - acc: 0.9603 - val_loss: 0.1159 - val_acc: 0.9649\n",
            "Epoch 6/10\n",
            "64000/64000 [==============================] - 29s 447us/step - loss: 0.1259 - acc: 0.9615 - val_loss: 0.1159 - val_acc: 0.9646\n",
            "Epoch 7/10\n",
            "64000/64000 [==============================] - 28s 445us/step - loss: 0.1264 - acc: 0.9615 - val_loss: 0.1148 - val_acc: 0.9646\n",
            "Epoch 8/10\n",
            "64000/64000 [==============================] - 29s 453us/step - loss: 0.1246 - acc: 0.9618 - val_loss: 0.1136 - val_acc: 0.9657\n",
            "Epoch 9/10\n",
            "64000/64000 [==============================] - 29s 455us/step - loss: 0.1237 - acc: 0.9619 - val_loss: 0.1112 - val_acc: 0.9663\n",
            "Epoch 10/10\n",
            "64000/64000 [==============================] - 28s 445us/step - loss: 0.1224 - acc: 0.9629 - val_loss: 0.1120 - val_acc: 0.9665\n",
            "20000/20000 [==============================] - 84s 4ms/step\n",
            "[0.12098813403770328, 0.96195]\n",
            "[[ 2 23  2 10 13  2  3 13  6 42  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [21  9  6 38  9  6 10  8  9 21 38 21 16 38 22 20  6 38  7 16 19 38 21  9\n",
            "   6 38 19 10  4  9 38 21  6 25 21 38  2 19  6  2 38 10 15 38 21  9  6 38\n",
            "   4 16 17 26 48 17  2 21  6 38  5 10  2 13 16  8 40 38 10 15 38 17 25 42\n",
            "  38 38  5  6  7  2 22 13 21 38 10 20 38 31 28 28 17 25 42  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 4 13 10  6 15 21 29 42  8  6 21 19  6  2  5  6 15  5 17 16 10 15 21 64\n",
            "  64  6 19 19 45 38  5  5  3 42 18 22  6 19 26  6 19 19 16 19 40 38 19  6\n",
            "  20 16 22 19  4  6 45 38 20 21 19 10 15  8 40 38 19  6 20 17 16 15 20  6\n",
            "   9  6  2  5  6 19 20 45 38  2 15 26 65 38 63 71 38 23 16 10  5 38 28 65\n",
            "  41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [19  6 21 22 19 15 38 21 26 17  6 38 63 63 38 10 20 51  4 23 38 50 50 38\n",
            "  21 26 17  6 38 63 63 38 10 20 51 23  2 19 38 50 50 38 21 26 17  6 38 63\n",
            "  63 38 10 20 51 21 14 17 51 23  2 19 41  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [42 21 19 10 14 64 65 40  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]]\n",
            "Train on 64000 samples, validate on 16000 samples\n",
            "Epoch 1/10\n",
            "64000/64000 [==============================] - 28s 443us/step - loss: 0.1280 - acc: 0.9612 - val_loss: 0.1163 - val_acc: 0.9646\n",
            "Epoch 2/10\n",
            "64000/64000 [==============================] - 28s 445us/step - loss: 0.1269 - acc: 0.9621 - val_loss: 0.1159 - val_acc: 0.9652\n",
            "Epoch 3/10\n",
            "64000/64000 [==============================] - 28s 443us/step - loss: 0.1253 - acc: 0.9624 - val_loss: 0.1157 - val_acc: 0.9649\n",
            "Epoch 4/10\n",
            "64000/64000 [==============================] - 28s 441us/step - loss: 0.1250 - acc: 0.9623 - val_loss: 0.1152 - val_acc: 0.9657\n",
            "Epoch 5/10\n",
            "64000/64000 [==============================] - 28s 444us/step - loss: 0.1246 - acc: 0.9621 - val_loss: 0.1142 - val_acc: 0.9664\n",
            "Epoch 6/10\n",
            "64000/64000 [==============================] - 29s 446us/step - loss: 0.1224 - acc: 0.9628 - val_loss: 0.1141 - val_acc: 0.9658\n",
            "Epoch 7/10\n",
            "64000/64000 [==============================] - 28s 443us/step - loss: 0.1235 - acc: 0.9635 - val_loss: 0.1138 - val_acc: 0.9655\n",
            "Epoch 8/10\n",
            "64000/64000 [==============================] - 28s 443us/step - loss: 0.1223 - acc: 0.9635 - val_loss: 0.1130 - val_acc: 0.9661\n",
            "Epoch 9/10\n",
            "64000/64000 [==============================] - 29s 446us/step - loss: 0.1202 - acc: 0.9645 - val_loss: 0.1124 - val_acc: 0.9668\n",
            "Epoch 10/10\n",
            "64000/64000 [==============================] - 29s 451us/step - loss: 0.1199 - acc: 0.9640 - val_loss: 0.1125 - val_acc: 0.9662\n",
            "20000/20000 [==============================] - 83s 4ms/step\n",
            "[0.10249678262248635, 0.9691]\n",
            "[[15 16  5  6 42 17 19 16 17  6 19 21 10  6 20  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [15 16  5  6 38 63 38 15 16  5  6 42 17  2 19  6 15 21 41  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [52  2 22 21  9 16 19 38 12  6 23 10 15 38  3 16 22 19 19 10 13 13 10 16\n",
            "  15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [10 14 17 16 19 21 38 16 19  8 42  6 13  2 20 21 10  4 20  6  2 19  4  9\n",
            "  42 20  4 19 10 17 21 42 20  4 19 10 17 21 41  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [17 19  6 17  2 19  6 23  6 19 20 10 16 15 40  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]]\n",
            "Train on 64000 samples, validate on 16000 samples\n",
            "Epoch 1/10\n",
            "64000/64000 [==============================] - 29s 447us/step - loss: 0.1236 - acc: 0.9632 - val_loss: 0.1042 - val_acc: 0.9681\n",
            "Epoch 2/10\n",
            "64000/64000 [==============================] - 29s 450us/step - loss: 0.1233 - acc: 0.9633 - val_loss: 0.1046 - val_acc: 0.9686\n",
            "Epoch 3/10\n",
            "64000/64000 [==============================] - 29s 447us/step - loss: 0.1233 - acc: 0.9637 - val_loss: 0.1033 - val_acc: 0.9686\n",
            "Epoch 4/10\n",
            "64000/64000 [==============================] - 29s 451us/step - loss: 0.1231 - acc: 0.9630 - val_loss: 0.1033 - val_acc: 0.9694\n",
            "Epoch 5/10\n",
            "64000/64000 [==============================] - 28s 444us/step - loss: 0.1213 - acc: 0.9645 - val_loss: 0.1030 - val_acc: 0.9697\n",
            "Epoch 6/10\n",
            "64000/64000 [==============================] - 28s 442us/step - loss: 0.1193 - acc: 0.9648 - val_loss: 0.1017 - val_acc: 0.9699\n",
            "Epoch 7/10\n",
            "64000/64000 [==============================] - 29s 445us/step - loss: 0.1184 - acc: 0.9651 - val_loss: 0.1026 - val_acc: 0.9698\n",
            "Epoch 8/10\n",
            "64000/64000 [==============================] - 28s 445us/step - loss: 0.1192 - acc: 0.9653 - val_loss: 0.1021 - val_acc: 0.9696\n",
            "Epoch 9/10\n",
            "64000/64000 [==============================] - 28s 443us/step - loss: 0.1182 - acc: 0.9652 - val_loss: 0.1014 - val_acc: 0.9698\n",
            "Epoch 10/10\n",
            "64000/64000 [==============================] - 29s 450us/step - loss: 0.1180 - acc: 0.9661 - val_loss: 0.1010 - val_acc: 0.9702\n",
            "20000/20000 [==============================] - 83s 4ms/step\n",
            "[0.10024264491647482, 0.9699]\n",
            "[[ 2 19  6 38 10  8 15 16 19  6  5 40 38  3 22 21 38 10 15 38  4  2 20  6\n",
            "  38 21  9  6 38  7 16 19  4  6 38 16 17 21 10 16 15 38 10 20 38 22 20  6\n",
            "   5 42 38 10 15 38 21  9  2 21 38  4  2 20  6 38 24  6  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [10 15 21 31 30 51 21 38  9  6 10  8  9 21 65  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [20  6 20 20 10 16 15 20 42 17 22 20  9 64 20  6 20 20 10 16 15 65 41  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [20  6 21 64 17 19 16 17  6 19 21 26 45 47 20 21 26 13  6 47 40 38 23  2\n",
            "  13 22  6 45 38 20 21 19 10 15  8 65 45 38 23 16 10  5 41  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 2 38 19  6 20 16 22 19  4  6 38  3 22 15  5 13  6 38 14 22 20 21 38  4\n",
            "  16 15 21  2 10 15 38  2 21 38 13  6  2 20 21 38 16 15  6 38 19  6 20 16\n",
            "  22 19  4  6 38 10 21  6 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]]\n",
            "Train on 64000 samples, validate on 16000 samples\n",
            "Epoch 1/10\n",
            "64000/64000 [==============================] - 28s 444us/step - loss: 0.1174 - acc: 0.9664 - val_loss: 0.1029 - val_acc: 0.9694\n",
            "Epoch 2/10\n",
            "64000/64000 [==============================] - 28s 445us/step - loss: 0.1158 - acc: 0.9668 - val_loss: 0.1033 - val_acc: 0.9699\n",
            "Epoch 3/10\n",
            "64000/64000 [==============================] - 28s 441us/step - loss: 0.1149 - acc: 0.9671 - val_loss: 0.1008 - val_acc: 0.9701\n",
            "Epoch 4/10\n",
            "64000/64000 [==============================] - 28s 438us/step - loss: 0.1139 - acc: 0.9672 - val_loss: 0.1007 - val_acc: 0.9698\n",
            "Epoch 5/10\n",
            "64000/64000 [==============================] - 29s 447us/step - loss: 0.1148 - acc: 0.9669 - val_loss: 0.1010 - val_acc: 0.9702\n",
            "Epoch 6/10\n",
            "64000/64000 [==============================] - 28s 438us/step - loss: 0.1127 - acc: 0.9679 - val_loss: 0.1001 - val_acc: 0.9704\n",
            "Epoch 7/10\n",
            "64000/64000 [==============================] - 28s 436us/step - loss: 0.1120 - acc: 0.9679 - val_loss: 0.1006 - val_acc: 0.9709\n",
            "Epoch 8/10\n",
            "64000/64000 [==============================] - 28s 439us/step - loss: 0.1125 - acc: 0.9681 - val_loss: 0.1015 - val_acc: 0.9697\n",
            "Epoch 9/10\n",
            "64000/64000 [==============================] - 28s 436us/step - loss: 0.1112 - acc: 0.9687 - val_loss: 0.0986 - val_acc: 0.9709\n",
            "Epoch 10/10\n",
            "64000/64000 [==============================] - 28s 441us/step - loss: 0.1117 - acc: 0.9684 - val_loss: 0.0986 - val_acc: 0.9709\n",
            "20000/20000 [==============================] - 83s 4ms/step\n",
            "[0.0936245467916131, 0.9719]\n",
            "[[20  6 21 21 10 15  8 42 17 19 16 17  6 19 21 26 42 15 16  5  6 20  4 16\n",
            "  17  6 65 65 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [68 38 47 17 13  2 15  6 20 47 40 38 47 20  6 21 38 17 13  2 15  6 20 38\n",
            "  21 16 38  7 10 13 21  6 19 47 40 38 16  7  7 20  6 21 64 17 13  2 15  6\n",
            "  20 65 40 38  2 23 51 16 17 21 51 21 26 17  6 51 10 15 21 40 38 38 68 42\n",
            "  10 34 32 63 29 33 69 40 38 28 40 38 29 33 40 38  7 13  2  8 20 69 40  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 6 25 17  6  4 21 64 64 65 38 63 71 38  4 16 13 13  6  4 21 16 19 42  8\n",
            "   6 21 14  6 21  2  5  2 21  2 64 10 15 23  2 13 10  5  7 22 15  4 21 10\n",
            "  16 15 65 65 42 15 16 21 42 21 16 21  9 19 16 24 64 65 41  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 4 16 15 20 21 38 17  2 19  4  6 13 16 17 21 10 16 15 45 38 17  2 19  4\n",
            "   6 13 16 17 21 10 16 15 20 38 63 38 68 38 24  2 21  4  9 45 38  7  2 13\n",
            "  20  6 38 69 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 4 16 17 26 38 21  9  6 38  4 16 15 21  6 15 21 20 38 16  7 38 20  2 14\n",
            "  17 13  6 38 17 15  6 24 38 10 15 21 16 38 21  9  6 38 17 62 71  2 66 67\n",
            "  38  2 19 19  2 26 42 38 10  7 38 15  6  4  6 20 20  2 19 26 40  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]]\n",
            "Train on 64000 samples, validate on 16000 samples\n",
            "Epoch 1/10\n",
            "64000/64000 [==============================] - 28s 439us/step - loss: 0.1129 - acc: 0.9675 - val_loss: 0.1004 - val_acc: 0.9713\n",
            "Epoch 2/10\n",
            "64000/64000 [==============================] - 28s 437us/step - loss: 0.1119 - acc: 0.9685 - val_loss: 0.0996 - val_acc: 0.9715\n",
            "Epoch 3/10\n",
            "64000/64000 [==============================] - 28s 444us/step - loss: 0.1107 - acc: 0.9684 - val_loss: 0.0994 - val_acc: 0.9721\n",
            "Epoch 4/10\n",
            "64000/64000 [==============================] - 28s 437us/step - loss: 0.1100 - acc: 0.9691 - val_loss: 0.0989 - val_acc: 0.9721\n",
            "Epoch 5/10\n",
            "64000/64000 [==============================] - 28s 440us/step - loss: 0.1101 - acc: 0.9690 - val_loss: 0.0982 - val_acc: 0.9724\n",
            "Epoch 6/10\n",
            "64000/64000 [==============================] - 28s 442us/step - loss: 0.1088 - acc: 0.9687 - val_loss: 0.0977 - val_acc: 0.9719\n",
            "Epoch 7/10\n",
            "64000/64000 [==============================] - 28s 442us/step - loss: 0.1074 - acc: 0.9695 - val_loss: 0.0975 - val_acc: 0.9727\n",
            "Epoch 8/10\n",
            "64000/64000 [==============================] - 28s 445us/step - loss: 0.1060 - acc: 0.9698 - val_loss: 0.0981 - val_acc: 0.9726\n",
            "Epoch 9/10\n",
            "64000/64000 [==============================] - 29s 445us/step - loss: 0.1063 - acc: 0.9702 - val_loss: 0.0982 - val_acc: 0.9721\n",
            "Epoch 10/10\n",
            "64000/64000 [==============================] - 29s 446us/step - loss: 0.1063 - acc: 0.9694 - val_loss: 0.0969 - val_acc: 0.9730\n",
            "20000/20000 [==============================] - 83s 4ms/step\n",
            "[0.10106348056793213, 0.97045]\n",
            "[[10 15 21 38  6 40 38 10 15 21 38 10 40 38 10 15 21 38  9 65  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [69 65 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [19  6 21 22 19 15 38 20  6 13  7 42 51  4 22 19 51  8 19  2 17  9 42 10\n",
            "   5 51 21 16 51 10 15  5  6 25 66 20  6 13  7 42 51  4 22 19 51 10 14  2\n",
            "   8  6 51 10  5 67  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [10 14 17 16 19 21 38 16 19  8 42  6 13  2 20 21 10  4 20  6  2 19  4  9\n",
            "  42 25 17  2  4 12 42  4 16 19  6 42  4  4 19 42  2  4 21 10 16 15 42  7\n",
            "  16 13 13 16 24 10 15  7 16  2  4 21 10 16 15 41  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [42  4  2 13 13  6  5 24 10 21  9 64 32 65 42 14 16  4 12 19  6 21 22 19\n",
            "  15 23  2 13 22  6 64 46 24  2 26 43 46 65 41  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]]\n",
            "Train on 64000 samples, validate on 16000 samples\n",
            "Epoch 1/10\n",
            "48128/64000 [=====================>........] - ETA: 6s - loss: 0.1109 - acc: 0.9686"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-9499608420fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m80000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m80000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m80000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m80000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zf9zeS_cciz",
        "colab_type": "code",
        "outputId": "3fe436bb-1129-42a6-b8e5-5e1d85e156ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1303
        }
      },
      "source": [
        "dft = val.sample(n=100000)\n",
        "y = dft['is_code']\n",
        "X_test = transform_sentences(dft)\n",
        "p = model.predict(X_test)\n",
        "for i in range(10):\n",
        "  print(y[i],p[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10 14 17 16 19 21 21 26 17  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 8 13 51 21  6 20 20 51  6 23  2 13 22  2 21 10 16 15 51 20 22  3 19 16\n",
            "  22 21 10 15  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [51 51 21 10  3 51 11  2 23  2 51 13  2 15  8 51  3 26 21  6 42 23 21  2\n",
            "   3 13  6 66 29 28 67 38 63 38 64 23 21  2  3 13  6 51 17 21 19 65 38 57\n",
            "  11  2 23  2 51 13  2 15  8 51  3 26 21  6 51 13 16 15  8 23  2 13 22  6\n",
            "  51 51 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [21  6 25 21 22 19  6 38 16  3 11  6  4 21 38  9  2 15  5 13  6  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 7 22 15  4 21 10 16 15 38  7 16 16 64 65 38 68 69  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-396c255e577e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 4375\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   4376\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr7LemQ7-Zwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "def ROC_CURVE(y,p):\n",
        "  fpr, tpr, _ = metrics.roc_curve(y, p)\n",
        "\n",
        "  plt.figure(figsize=(7, 7))\n",
        "  lw = 2\n",
        "  plt.plot(fpr, tpr, color='royalblue',lw=2)\n",
        "  plt.plot([0, 1], [0, 1], color='Black', lw=2, ls='--')\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('Curva ROC')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLEKCWJUtFGi",
        "colab_type": "code",
        "outputId": "6d55aea0-21b9-4f8b-b7a8-df767d5baaf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "ROC_CURVE(y,p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcEAAAG5CAYAAAD2yo9EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsqIIhhBCqKwogiGEECrrP5cmrA7L0WyUAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3rdr6awdvih",
        "colab_type": "code",
        "outputId": "0efa4d4e-1e4d-400a-faf8-7f5865d38413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "p2 = [1 if pred > 0.6 else 0 for pred in p]\n",
        "cm = metrics.confusion_matrix(y, p2)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 7))\n",
        "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "ax.figure.colorbar(im, ax=ax)\n",
        "ax.set(xticks=np.arange(cm.shape[1]),\n",
        "       yticks=np.arange(cm.shape[0]),\n",
        "       xticklabels=['comment','code'], yticklabels=['comment','code'],\n",
        "       title=\"Matriz de Confusão\",\n",
        "       ylabel=\"Real\",\n",
        "       xlabel=\"Predito\")\n",
        "\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "         rotation_mode=\"anchor\")\n",
        "\n",
        "for i in range(cm.shape[0]):\n",
        "  for j in range(cm.shape[1]):\n",
        "    ax.text(j, i, format(cm[i, j], \"d\"),\n",
        "            ha=\"center\", va=\"center\",\n",
        "            color=\"white\" if cm[i, j] > cm.max()/2. else \"black\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAHYCAYAAABk9mDYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIq5v8Dx9WA1EoKl+UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 504x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU6ZjRIg8_1Z",
        "colab_type": "code",
        "outputId": "e6e4f573-24cd-4ab2-9447-5d9232a25639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "precision = 80455/(80455+1682)\n",
        "revoc = 80455/(80455+1129)\n",
        "acc = (80455+16734)/(16734+1682+1129+80455)\n",
        "print('Precisão:' + str(precision))\n",
        "print('Revocação:' + str(revoc))\n",
        "print('Acurácia:' + str(acc))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisão:0.9795220180917248\n",
            "Revocação:0.9861615022553442\n",
            "Acurácia:0.97189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb3CnsFOUY4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0fc51434-7241-44d9-9ba8-f8e158451031"
      },
      "source": [
        "precision = 80224/(80224+1516)\n",
        "revoc = 80224/(80224+1360)\n",
        "acc = (80224+16900)/(16900+1516+1360+80224)\n",
        "print('Precisão:' + str(precision))\n",
        "print('Revocação:' + str(revoc))\n",
        "print('Acurácia:' + str(acc))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisão:0.9814533887937362\n",
            "Revocação:0.9833300647185723\n",
            "Acurácia:0.97124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arXtqhbf-L0f",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}